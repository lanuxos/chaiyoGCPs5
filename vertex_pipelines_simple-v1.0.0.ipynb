{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6x1ypzczQCwy"
   },
   "source": [
    "# Simple TFX Pipeline for Vertex Pipelines\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_VuwrlnvQJ5k"
   },
   "source": [
    "This notebook-based tutorial will create a simple TFX pipeline and run it using\n",
    "Google Cloud Vertex Pipelines.  This notebook is based on the TFX pipeline\n",
    "built in\n",
    "[Simple TFX Pipeline Tutorial](https://www.tensorflow.org/tfx/tutorials/tfx/penguin_simple).\n",
    "\n",
    "Google Cloud Vertex Pipelines helps you to automate, monitor, and govern\n",
    "your ML systems by orchestrating your ML workflow in a serverless manner. You\n",
    "can define your ML pipelines using Python with TFX, and then execute your\n",
    "pipelines on Google Cloud. See\n",
    "[Vertex Pipelines introduction](https://cloud.google.com/vertex-ai/docs/pipelines/introduction)\n",
    "to learn more about Vertex Pipelines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fwZ0aXisoBFW"
   },
   "source": [
    "## Setup\n",
    "### Install python packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WC9W_S-bONgl"
   },
   "source": [
    "We will install required Python packages including TFX and KFP to author ML\n",
    "pipelines and submit jobs to Vertex Pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "iyQtljP-qPHY",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /opt/conda/lib/python3.10/site-packages (25.0)\n",
      "Collecting pip\n",
      "  Downloading pip-25.0.1-py3-none-any.whl.metadata (3.7 kB)\n",
      "Downloading pip-25.0.1-py3-none-any.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m37.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 25.0\n",
      "    Uninstalling pip-25.0:\n",
      "      Successfully uninstalled pip-25.0\n",
      "Successfully installed pip-25.0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\u001b[33mWARNING: Skipping tensorflow as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping tensorflow-tensorboard as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping tensorflow-io as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping tensorflow-cloud as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "Collecting tensorflow==2.15.1\n",
      "  Downloading tensorflow-2.15.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.1) (2.1.0)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow==2.15.1)\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=23.5.26 (from tensorflow==2.15.1)\n",
      "  Downloading flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow==2.15.1)\n",
      "  Downloading gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow==2.15.1)\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting h5py>=2.9.0 (from tensorflow==2.15.1)\n",
      "  Downloading h5py-3.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.5 kB)\n",
      "Collecting libclang>=13.0.0 (from tensorflow==2.15.1)\n",
      "  Downloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl.metadata (5.2 kB)\n",
      "Collecting ml-dtypes~=0.3.1 (from tensorflow==2.15.1)\n",
      "  Downloading ml_dtypes-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.1) (1.26.4)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow==2.15.1)\n",
      "  Downloading opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.1) (24.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.1) (3.20.3)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.1) (75.8.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.1) (1.17.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow==2.15.1)\n",
      "  Downloading termcolor-2.5.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.1) (4.12.2)\n",
      "Collecting wrapt<1.15,>=1.11.0 (from tensorflow==2.15.1)\n",
      "  Downloading wrapt-1.14.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow==2.15.1)\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.37.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.1) (1.70.0)\n",
      "Collecting tensorboard<2.16,>=2.15 (from tensorflow==2.15.1)\n",
      "  Downloading tensorboard-2.15.2-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting tensorflow-estimator<2.16,>=2.15.0 (from tensorflow==2.15.1)\n",
      "  Downloading tensorflow_estimator-2.15.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting keras<2.16,>=2.15.0 (from tensorflow==2.15.1)\n",
      "  Downloading keras-2.15.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow==2.15.1) (0.45.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.1) (2.38.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.1) (1.2.1)\n",
      "Collecting markdown>=2.6.8 (from tensorboard<2.16,>=2.15->tensorflow==2.15.1)\n",
      "  Downloading Markdown-3.7-py3-none-any.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.1) (2.32.3)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.16,>=2.15->tensorflow==2.15.1)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard<2.16,>=2.15->tensorflow==2.15.1)\n",
      "  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.1) (5.5.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.1) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.1) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow==2.15.1) (2.0.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.1) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.1) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.1) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.1) (2024.12.14)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow==2.15.1) (3.0.2)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.1) (0.6.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow==2.15.1) (3.2.2)\n",
      "Downloading tensorflow-2.15.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (475.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m475.2/475.2 MB\u001b[0m \u001b[31m42.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Downloading flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
      "Downloading gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Downloading h5py-3.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading keras-2.15.0-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl (24.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.5/24.5 MB\u001b[0m \u001b[31m32.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading ml_dtypes-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Downloading tensorboard-2.15.2-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hDownloading tensorflow_estimator-2.15.0-py2.py3-none-any.whl (441 kB)\n",
      "Downloading tensorflow_io_gcs_filesystem-0.37.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m63.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading termcolor-2.5.0-py3-none-any.whl (7.8 kB)\n",
      "Downloading wrapt-1.14.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (77 kB)\n",
      "Downloading Markdown-3.7-py3-none-any.whl (106 kB)\n",
      "Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m53.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "Installing collected packages: libclang, flatbuffers, wrapt, werkzeug, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard-data-server, opt-einsum, ml-dtypes, markdown, keras, h5py, google-pasta, gast, astunparse, tensorboard, tensorflow\n",
      "  Attempting uninstall: wrapt\n",
      "    Found existing installation: wrapt 1.17.2\n",
      "    Uninstalling wrapt-1.17.2:\n",
      "      Successfully uninstalled wrapt-1.17.2\n",
      "Successfully installed astunparse-1.6.3 flatbuffers-25.2.10 gast-0.6.0 google-pasta-0.2.0 h5py-3.13.0 keras-2.15.0 libclang-18.1.1 markdown-3.7 ml-dtypes-0.3.2 opt-einsum-3.4.0 tensorboard-2.15.2 tensorboard-data-server-0.7.2 tensorflow-2.15.1 tensorflow-estimator-2.15.0 tensorflow-io-gcs-filesystem-0.37.1 termcolor-2.5.0 werkzeug-3.1.3 wrapt-1.14.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\u001b[33mWARNING: Skipping tfx as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "Collecting tfx==1.15.0 (from tfx[kfp]==1.15.0)\n",
      "  Downloading tfx-1.15.0-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting ml-pipelines-sdk==1.15.0 (from tfx==1.15.0->tfx[kfp]==1.15.0)\n",
      "  Downloading ml_pipelines_sdk-1.15.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting absl-py<2.0.0,>=0.9 (from tfx==1.15.0->tfx[kfp]==1.15.0)\n",
      "  Downloading absl_py-1.4.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting ml-metadata<1.16.0,>=1.15.0 (from tfx==1.15.0->tfx[kfp]==1.15.0)\n",
      "  Downloading ml_metadata-1.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: packaging>=22 in /opt/conda/lib/python3.10/site-packages (from tfx==1.15.0->tfx[kfp]==1.15.0) (24.2)\n",
      "Collecting portpicker<2,>=1.3.1 (from tfx==1.15.0->tfx[kfp]==1.15.0)\n",
      "  Downloading portpicker-1.6.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: protobuf<5,>=3.20.3 in /opt/conda/lib/python3.10/site-packages (from tfx==1.15.0->tfx[kfp]==1.15.0) (3.20.3)\n",
      "Collecting docker<5,>=4.1 (from tfx==1.15.0->tfx[kfp]==1.15.0)\n",
      "  Downloading docker-4.4.4-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting google-apitools<1,>=0.5 (from tfx==1.15.0->tfx[kfp]==1.15.0)\n",
      "  Downloading google_apitools-0.5.32-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: google-api-python-client<2,>=1.8 in /opt/conda/lib/python3.10/site-packages (from tfx==1.15.0->tfx[kfp]==1.15.0) (1.8.0)\n",
      "Requirement already satisfied: jinja2<4,>=2.7.3 in /opt/conda/lib/python3.10/site-packages (from tfx==1.15.0->tfx[kfp]==1.15.0) (3.1.5)\n",
      "Requirement already satisfied: typing-extensions<5,>=3.10.0.2 in /opt/conda/lib/python3.10/site-packages (from tfx==1.15.0->tfx[kfp]==1.15.0) (4.12.2)\n",
      "Collecting apache-beam<3,>=2.47 (from apache-beam[gcp]<3,>=2.47->tfx==1.15.0->tfx[kfp]==1.15.0)\n",
      "  Downloading apache_beam-2.63.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.3 kB)\n",
      "Collecting attrs<24,>=19.3.0 (from tfx==1.15.0->tfx[kfp]==1.15.0)\n",
      "  Downloading attrs-23.2.0-py3-none-any.whl.metadata (9.5 kB)\n",
      "Requirement already satisfied: click<9,>=7 in /opt/conda/lib/python3.10/site-packages (from tfx==1.15.0->tfx[kfp]==1.15.0) (8.1.8)\n",
      "Requirement already satisfied: google-api-core<3 in /opt/conda/lib/python3.10/site-packages (from tfx==1.15.0->tfx[kfp]==1.15.0) (1.34.1)\n",
      "Requirement already satisfied: google-cloud-aiplatform<2,>=1.6.2 in /opt/conda/lib/python3.10/site-packages (from tfx==1.15.0->tfx[kfp]==1.15.0) (1.79.0)\n",
      "Requirement already satisfied: google-cloud-bigquery<4,>=3 in /opt/conda/lib/python3.10/site-packages (from tfx==1.15.0->tfx[kfp]==1.15.0) (3.25.0)\n",
      "Requirement already satisfied: grpcio<2,>=1.28.1 in /opt/conda/lib/python3.10/site-packages (from tfx==1.15.0->tfx[kfp]==1.15.0) (1.70.0)\n",
      "Collecting keras-tuner!=1.4.0,!=1.4.1,<2,>=1.0.4 (from tfx==1.15.0->tfx[kfp]==1.15.0)\n",
      "  Downloading keras_tuner-1.4.7-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting kubernetes<13,>=10.0.1 (from tfx==1.15.0->tfx[kfp]==1.15.0)\n",
      "  Downloading kubernetes-12.0.1-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: numpy<2,>=1.16 in /opt/conda/lib/python3.10/site-packages (from tfx==1.15.0->tfx[kfp]==1.15.0) (1.26.4)\n",
      "Collecting pyarrow<11,>=10 (from tfx==1.15.0->tfx[kfp]==1.15.0)\n",
      "  Downloading pyarrow-10.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
      "Collecting scipy<1.13 (from tfx==1.15.0->tfx[kfp]==1.15.0)\n",
      "  Downloading scipy-1.12.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "Requirement already satisfied: pyyaml<7,>=6 in /opt/conda/lib/python3.10/site-packages (from tfx==1.15.0->tfx[kfp]==1.15.0) (6.0.2)\n",
      "Requirement already satisfied: tensorflow<2.16,>=2.15.0 in /opt/conda/lib/python3.10/site-packages (from tfx==1.15.0->tfx[kfp]==1.15.0) (2.15.1)\n",
      "Collecting tensorflow-hub<0.16,>=0.15.0 (from tfx==1.15.0->tfx[kfp]==1.15.0)\n",
      "  Downloading tensorflow_hub-0.15.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting tensorflow-data-validation<1.16.0,>=1.15.1 (from tfx==1.15.0->tfx[kfp]==1.15.0)\n",
      "  Downloading tensorflow_data_validation-1.15.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
      "Collecting tensorflow-model-analysis<0.47.0,>=0.46.0 (from tfx==1.15.0->tfx[kfp]==1.15.0)\n",
      "  Downloading tensorflow_model_analysis-0.46.0-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting tensorflow-serving-api<2.16,>=2.15 (from tfx==1.15.0->tfx[kfp]==1.15.0)\n",
      "  Downloading tensorflow_serving_api-2.15.1-py2.py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting tensorflow-transform<1.16.0,>=1.15.0 (from tfx==1.15.0->tfx[kfp]==1.15.0)\n",
      "  Downloading tensorflow_transform-1.15.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting tfx-bsl<1.16.0,>=1.15.1 (from tfx==1.15.0->tfx[kfp]==1.15.0)\n",
      "  Downloading tfx_bsl-1.15.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Collecting kfp<2,>=1.8.14 (from tfx[kfp]==1.15.0)\n",
      "  Downloading kfp-1.8.22.tar.gz (304 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting kfp-pipeline-spec<0.2,>=0.1.10 (from tfx[kfp]==1.15.0)\n",
      "  Downloading kfp_pipeline_spec-0.1.16-py3-none-any.whl.metadata (323 bytes)\n",
      "Collecting crcmod<2.0,>=1.7 (from apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx==1.15.0->tfx[kfp]==1.15.0)\n",
      "  Downloading crcmod-1.7.tar.gz (89 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting orjson<4,>=3.9.7 (from apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx==1.15.0->tfx[kfp]==1.15.0)\n",
      "  Downloading orjson-3.10.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (41 kB)\n",
      "Collecting dill<0.3.2,>=0.3.1.1 (from apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx==1.15.0->tfx[kfp]==1.15.0)\n",
      "  Downloading dill-0.3.1.1.tar.gz (151 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting cloudpickle~=2.2.1 (from apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx==1.15.0->tfx[kfp]==1.15.0)\n",
      "  Downloading cloudpickle-2.2.1-py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting fastavro<2,>=0.23.6 (from apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx==1.15.0->tfx[kfp]==1.15.0)\n",
      "  Downloading fastavro-1.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n",
      "Collecting fasteners<1.0,>=0.3 (from apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx==1.15.0->tfx[kfp]==1.15.0)\n",
      "  Downloading fasteners-0.19-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting grpcio<2,>=1.28.1 (from tfx==1.15.0->tfx[kfp]==1.15.0)\n",
      "  Downloading grpcio-1.65.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.3 kB)\n",
      "Collecting hdfs<3.0.0,>=2.1.0 (from apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx==1.15.0->tfx[kfp]==1.15.0)\n",
      "  Downloading hdfs-2.7.3.tar.gz (43 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: httplib2<0.23.0,>=0.8 in /opt/conda/lib/python3.10/site-packages (from apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx==1.15.0->tfx[kfp]==1.15.0) (0.22.0)\n",
      "Requirement already satisfied: jsonschema<5.0.0,>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx==1.15.0->tfx[kfp]==1.15.0) (4.23.0)\n",
      "Collecting jsonpickle<4.0.0,>=3.0.0 (from apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx==1.15.0->tfx[kfp]==1.15.0)\n",
      "  Downloading jsonpickle-3.4.2-py3-none-any.whl.metadata (8.1 kB)\n",
      "Collecting objsize<0.8.0,>=0.6.1 (from apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx==1.15.0->tfx[kfp]==1.15.0)\n",
      "  Downloading objsize-0.7.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting pymongo<5.0.0,>=3.8.0 (from apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx==1.15.0->tfx[kfp]==1.15.0)\n",
      "  Downloading pymongo-4.11.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (22 kB)\n",
      "Requirement already satisfied: proto-plus<2,>=1.7.1 in /opt/conda/lib/python3.10/site-packages (from apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx==1.15.0->tfx[kfp]==1.15.0) (1.26.0)\n",
      "Collecting pydot<2,>=1.2.0 (from apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx==1.15.0->tfx[kfp]==1.15.0)\n",
      "  Downloading pydot-1.4.2-py2.py3-none-any.whl.metadata (8.0 kB)\n",
      "Requirement already satisfied: python-dateutil<3,>=2.8.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx==1.15.0->tfx[kfp]==1.15.0) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2018.3 in /opt/conda/lib/python3.10/site-packages (from apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx==1.15.0->tfx[kfp]==1.15.0) (2025.1)\n",
      "Collecting redis<6,>=5.0.0 (from apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx==1.15.0->tfx[kfp]==1.15.0)\n",
      "  Downloading redis-5.2.1-py3-none-any.whl.metadata (9.1 kB)\n",
      "Collecting regex>=2020.6.8 (from apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx==1.15.0->tfx[kfp]==1.15.0)\n",
      "  Downloading regex-2024.11.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.24.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx==1.15.0->tfx[kfp]==1.15.0) (2.32.3)\n",
      "Collecting sortedcontainers>=2.4.0 (from apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx==1.15.0->tfx[kfp]==1.15.0)\n",
      "  Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: zstandard<1,>=0.18.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx==1.15.0->tfx[kfp]==1.15.0) (0.23.0)\n",
      "Requirement already satisfied: pyarrow-hotfix<1 in /opt/conda/lib/python3.10/site-packages (from apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx==1.15.0->tfx[kfp]==1.15.0) (0.6)\n",
      "Requirement already satisfied: cachetools<6,>=3.1.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam[gcp]<3,>=2.47->tfx==1.15.0->tfx[kfp]==1.15.0) (5.5.1)\n",
      "Collecting google-api-core<3 (from tfx==1.15.0->tfx[kfp]==1.15.0)\n",
      "  Downloading google_api_core-2.24.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting google-apitools<1,>=0.5 (from tfx==1.15.0->tfx[kfp]==1.15.0)\n",
      "  Downloading google-apitools-0.5.31.tar.gz (173 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: google-auth<3,>=1.18.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam[gcp]<3,>=2.47->tfx==1.15.0->tfx[kfp]==1.15.0) (2.38.0)\n",
      "Requirement already satisfied: google-auth-httplib2<0.3.0,>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam[gcp]<3,>=2.47->tfx==1.15.0->tfx[kfp]==1.15.0) (0.2.0)\n",
      "Collecting google-cloud-datastore<3,>=2.0.0 (from apache-beam[gcp]<3,>=2.47->tfx==1.15.0->tfx[kfp]==1.15.0)\n",
      "  Downloading google_cloud_datastore-2.20.2-py2.py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting google-cloud-pubsub<3,>=2.1.0 (from apache-beam[gcp]<3,>=2.47->tfx==1.15.0->tfx[kfp]==1.15.0)\n",
      "  Downloading google_cloud_pubsub-2.28.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
      "Collecting google-cloud-pubsublite<2,>=1.2.0 (from apache-beam[gcp]<3,>=2.47->tfx==1.15.0->tfx[kfp]==1.15.0)\n",
      "  Downloading google_cloud_pubsublite-1.12.0-py2.py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting google-cloud-storage<3,>=2.18.2 (from apache-beam[gcp]<3,>=2.47->tfx==1.15.0->tfx[kfp]==1.15.0)\n",
      "  Downloading google_cloud_storage-2.19.0-py2.py3-none-any.whl.metadata (9.1 kB)\n",
      "Requirement already satisfied: google-cloud-bigquery-storage<3,>=2.6.3 in /opt/conda/lib/python3.10/site-packages (from apache-beam[gcp]<3,>=2.47->tfx==1.15.0->tfx[kfp]==1.15.0) (2.28.0)\n",
      "Requirement already satisfied: google-cloud-core<3,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam[gcp]<3,>=2.47->tfx==1.15.0->tfx[kfp]==1.15.0) (2.4.1)\n",
      "Collecting google-cloud-bigtable<3,>=2.19.0 (from apache-beam[gcp]<3,>=2.47->tfx==1.15.0->tfx[kfp]==1.15.0)\n",
      "  Downloading google_cloud_bigtable-2.29.0-py2.py3-none-any.whl.metadata (5.5 kB)\n",
      "Collecting google-cloud-spanner<4,>=3.0.0 (from apache-beam[gcp]<3,>=2.47->tfx==1.15.0->tfx[kfp]==1.15.0)\n",
      "  Downloading google_cloud_spanner-3.53.0-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Collecting google-cloud-dlp<4,>=3.0.0 (from apache-beam[gcp]<3,>=2.47->tfx==1.15.0->tfx[kfp]==1.15.0)\n",
      "  Downloading google_cloud_dlp-3.28.1-py3-none-any.whl.metadata (9.5 kB)\n",
      "Requirement already satisfied: google-cloud-language<3,>=2.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam[gcp]<3,>=2.47->tfx==1.15.0->tfx[kfp]==1.15.0) (2.16.0)\n",
      "Collecting google-cloud-videointelligence<3,>=2.0 (from apache-beam[gcp]<3,>=2.47->tfx==1.15.0->tfx[kfp]==1.15.0)\n",
      "  Downloading google_cloud_videointelligence-2.16.1-py3-none-any.whl.metadata (9.9 kB)\n",
      "Collecting google-cloud-vision<4,>=2 (from apache-beam[gcp]<3,>=2.47->tfx==1.15.0->tfx[kfp]==1.15.0)\n",
      "  Downloading google_cloud_vision-3.10.1-py3-none-any.whl.metadata (9.5 kB)\n",
      "Collecting google-cloud-recommendations-ai<0.11.0,>=0.1.0 (from apache-beam[gcp]<3,>=2.47->tfx==1.15.0->tfx[kfp]==1.15.0)\n",
      "  Downloading google_cloud_recommendations_ai-0.10.17-py3-none-any.whl.metadata (9.5 kB)\n",
      "Requirement already satisfied: keyrings.google-artifactregistry-auth in /opt/conda/lib/python3.10/site-packages (from apache-beam[gcp]<3,>=2.47->tfx==1.15.0->tfx[kfp]==1.15.0) (1.1.2)\n",
      "Requirement already satisfied: six>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from docker<5,>=4.1->tfx==1.15.0->tfx[kfp]==1.15.0) (1.17.0)\n",
      "Requirement already satisfied: websocket-client>=0.32.0 in /opt/conda/lib/python3.10/site-packages (from docker<5,>=4.1->tfx==1.15.0->tfx[kfp]==1.15.0) (1.8.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core<3->tfx==1.15.0->tfx[kfp]==1.15.0) (1.67.0rc1)\n",
      "INFO: pip is looking at multiple versions of google-api-python-client to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting google-api-python-client<2,>=1.8 (from tfx==1.15.0->tfx[kfp]==1.15.0)\n",
      "  Downloading google_api_python_client-1.12.11-py2.py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from google-api-python-client<2,>=1.8->tfx==1.15.0->tfx[kfp]==1.15.0) (3.0.1)\n",
      "Requirement already satisfied: oauth2client>=1.4.12 in /opt/conda/lib/python3.10/site-packages (from google-apitools<1,>=0.5->tfx==1.15.0->tfx[kfp]==1.15.0) (4.1.3)\n",
      "Requirement already satisfied: google-cloud-resource-manager<3.0.0dev,>=1.3.3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform<2,>=1.6.2->tfx==1.15.0->tfx[kfp]==1.15.0) (1.14.0)\n",
      "Requirement already satisfied: shapely<3.0.0dev in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform<2,>=1.6.2->tfx==1.15.0->tfx[kfp]==1.15.0) (2.0.7)\n",
      "Requirement already satisfied: pydantic<3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform<2,>=1.6.2->tfx==1.15.0->tfx[kfp]==1.15.0) (2.10.6)\n",
      "Requirement already satisfied: docstring-parser<1 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform<2,>=1.6.2->tfx==1.15.0->tfx[kfp]==1.15.0) (0.16)\n",
      "Requirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-bigquery<4,>=3->tfx==1.15.0->tfx[kfp]==1.15.0) (2.7.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2<4,>=2.7.3->tfx==1.15.0->tfx[kfp]==1.15.0) (3.0.2)\n",
      "Requirement already satisfied: keras in /opt/conda/lib/python3.10/site-packages (from keras-tuner!=1.4.0,!=1.4.1,<2,>=1.0.4->tfx==1.15.0->tfx[kfp]==1.15.0) (2.15.0)\n",
      "Collecting kt-legacy (from keras-tuner!=1.4.0,!=1.4.1,<2,>=1.0.4->tfx==1.15.0->tfx[kfp]==1.15.0)\n",
      "  Downloading kt_legacy-1.0.5-py3-none-any.whl.metadata (221 bytes)\n",
      "Requirement already satisfied: requests-toolbelt<1,>=0.8.0 in /opt/conda/lib/python3.10/site-packages (from kfp<2,>=1.8.14->tfx[kfp]==1.15.0) (0.10.1)\n",
      "Collecting kfp-server-api<2.0.0,>=1.1.2 (from kfp<2,>=1.8.14->tfx[kfp]==1.15.0)\n",
      "  Downloading kfp-server-api-1.8.5.tar.gz (58 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: tabulate<1,>=0.8.6 in /opt/conda/lib/python3.10/site-packages (from kfp<2,>=1.8.14->tfx[kfp]==1.15.0) (0.9.0)\n",
      "Requirement already satisfied: Deprecated<2,>=1.2.7 in /opt/conda/lib/python3.10/site-packages (from kfp<2,>=1.8.14->tfx[kfp]==1.15.0) (1.2.18)\n",
      "Collecting strip-hints<1,>=0.1.8 (from kfp<2,>=1.8.14->tfx[kfp]==1.15.0)\n",
      "  Downloading strip_hints-0.1.13-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting fire<1,>=0.3.1 (from kfp<2,>=1.8.14->tfx[kfp]==1.15.0)\n",
      "  Downloading fire-0.7.0.tar.gz (87 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: urllib3<2 in /opt/conda/lib/python3.10/site-packages (from kfp<2,>=1.8.14->tfx[kfp]==1.15.0) (1.26.20)\n",
      "Collecting pydantic<3 (from google-cloud-aiplatform<2,>=1.6.2->tfx==1.15.0->tfx[kfp]==1.15.0)\n",
      "  Downloading pydantic-1.10.21-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (153 kB)\n",
      "Collecting typer<1.0,>=0.3.2 (from kfp<2,>=1.8.14->tfx[kfp]==1.15.0)\n",
      "  Downloading typer-0.15.2-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: certifi>=14.05.14 in /opt/conda/lib/python3.10/site-packages (from kubernetes<13,>=10.0.1->tfx==1.15.0->tfx[kfp]==1.15.0) (2024.12.14)\n",
      "Requirement already satisfied: setuptools>=21.0.0 in /opt/conda/lib/python3.10/site-packages (from kubernetes<13,>=10.0.1->tfx==1.15.0->tfx[kfp]==1.15.0) (75.8.0)\n",
      "Requirement already satisfied: requests-oauthlib in /opt/conda/lib/python3.10/site-packages (from kubernetes<13,>=10.0.1->tfx==1.15.0->tfx[kfp]==1.15.0) (2.0.0)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from portpicker<2,>=1.3.1->tfx==1.15.0->tfx[kfp]==1.15.0) (5.9.3)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16,>=2.15.0->tfx==1.15.0->tfx[kfp]==1.15.0) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16,>=2.15.0->tfx==1.15.0->tfx[kfp]==1.15.0) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16,>=2.15.0->tfx==1.15.0->tfx[kfp]==1.15.0) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16,>=2.15.0->tfx==1.15.0->tfx[kfp]==1.15.0) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16,>=2.15.0->tfx==1.15.0->tfx[kfp]==1.15.0) (3.13.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16,>=2.15.0->tfx==1.15.0->tfx[kfp]==1.15.0) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16,>=2.15.0->tfx==1.15.0->tfx[kfp]==1.15.0) (0.3.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16,>=2.15.0->tfx==1.15.0->tfx[kfp]==1.15.0) (3.4.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16,>=2.15.0->tfx==1.15.0->tfx[kfp]==1.15.0) (2.5.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16,>=2.15.0->tfx==1.15.0->tfx[kfp]==1.15.0) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16,>=2.15.0->tfx==1.15.0->tfx[kfp]==1.15.0) (0.37.1)\n",
      "Requirement already satisfied: tensorboard<2.16,>=2.15 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16,>=2.15.0->tfx==1.15.0->tfx[kfp]==1.15.0) (2.15.2)\n",
      "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16,>=2.15.0->tfx==1.15.0->tfx[kfp]==1.15.0) (2.15.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow-data-validation<1.16.0,>=1.15.1->tfx==1.15.0->tfx[kfp]==1.15.0) (1.4.2)\n",
      "Collecting pandas<2,>=1.0 (from tensorflow-data-validation<1.16.0,>=1.15.1->tfx==1.15.0->tfx[kfp]==1.15.0)\n",
      "  Downloading pandas-1.5.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Collecting pyfarmhash<0.4,>=0.2.2 (from tensorflow-data-validation<1.16.0,>=1.15.1->tfx==1.15.0->tfx[kfp]==1.15.0)\n",
      "  Downloading pyfarmhash-0.3.2.tar.gz (99 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting tensorflow-metadata<1.16,>=1.15.0 (from tensorflow-data-validation<1.16.0,>=1.15.1->tfx==1.15.0->tfx[kfp]==1.15.0)\n",
      "  Downloading tensorflow_metadata-1.15.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting ipython<8,>=7 (from tensorflow-model-analysis<0.47.0,>=0.46.0->tfx==1.15.0->tfx[kfp]==1.15.0)\n",
      "  Downloading ipython-7.34.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting ipywidgets<8,>=7 (from tensorflow-model-analysis<0.47.0,>=0.46.0->tfx==1.15.0->tfx[kfp]==1.15.0)\n",
      "  Downloading ipywidgets-7.8.5-py2.py3-none-any.whl.metadata (1.9 kB)\n",
      "Requirement already satisfied: pillow>=9.4.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow-model-analysis<0.47.0,>=0.46.0->tfx==1.15.0->tfx[kfp]==1.15.0) (11.1.0)\n",
      "Collecting rouge-score<2,>=0.1.2 (from tensorflow-model-analysis<0.47.0,>=0.46.0->tfx==1.15.0->tfx[kfp]==1.15.0)\n",
      "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting sacrebleu<4,>=2.3 (from tensorflow-model-analysis<0.47.0,>=0.46.0->tfx==1.15.0->tfx[kfp]==1.15.0)\n",
      "  Downloading sacrebleu-2.5.1-py3-none-any.whl.metadata (51 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow<2.16,>=2.15.0->tfx==1.15.0->tfx[kfp]==1.15.0) (0.45.1)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform<2,>=1.6.2->tfx==1.15.0->tfx[kfp]==1.15.0) (1.49.0rc1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.18.0->apache-beam[gcp]<3,>=2.47->tfx==1.15.0->tfx[kfp]==1.15.0) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.18.0->apache-beam[gcp]<3,>=2.47->tfx==1.15.0->tfx[kfp]==1.15.0) (4.9)\n",
      "Requirement already satisfied: grpc-google-iam-v1<1.0.0dev,>=0.12.4 in /opt/conda/lib/python3.10/site-packages (from google-cloud-bigtable<3,>=2.19.0->apache-beam[gcp]<3,>=2.47->tfx==1.15.0->tfx[kfp]==1.15.0) (0.14.0)\n",
      "Requirement already satisfied: opentelemetry-api>=1.27.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-pubsub<3,>=2.1.0->apache-beam[gcp]<3,>=2.47->tfx==1.15.0->tfx[kfp]==1.15.0) (1.27.0)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.27.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-pubsub<3,>=2.1.0->apache-beam[gcp]<3,>=2.47->tfx==1.15.0->tfx[kfp]==1.15.0) (1.27.0)\n",
      "Requirement already satisfied: overrides<8.0.0,>=6.0.1 in /opt/conda/lib/python3.10/site-packages (from google-cloud-pubsublite<2,>=1.2.0->apache-beam[gcp]<3,>=2.47->tfx==1.15.0->tfx[kfp]==1.15.0) (7.7.0)\n",
      "Requirement already satisfied: sqlparse>=0.4.4 in /opt/conda/lib/python3.10/site-packages (from google-cloud-spanner<4,>=3.0.0->apache-beam[gcp]<3,>=2.47->tfx==1.15.0->tfx[kfp]==1.15.0) (0.5.3)\n",
      "Collecting grpc-interceptor>=0.15.4 (from google-cloud-spanner<4,>=3.0.0->apache-beam[gcp]<3,>=2.47->tfx==1.15.0->tfx[kfp]==1.15.0)\n",
      "  Downloading grpc_interceptor-0.15.4-py3-none-any.whl.metadata (8.4 kB)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-storage<3,>=2.18.2->apache-beam[gcp]<3,>=2.47->tfx==1.15.0->tfx[kfp]==1.15.0) (1.6.0)\n",
      "Collecting docopt (from hdfs<3.0.0,>=2.1.0->apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx==1.15.0->tfx[kfp]==1.15.0)\n",
      "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /opt/conda/lib/python3.10/site-packages (from httplib2<0.23.0,>=0.8->apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx==1.15.0->tfx[kfp]==1.15.0) (3.2.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.10/site-packages (from ipython<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx==1.15.0->tfx[kfp]==1.15.0) (0.19.2)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.10/site-packages (from ipython<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx==1.15.0->tfx[kfp]==1.15.0) (5.1.1)\n",
      "Collecting pickleshare (from ipython<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx==1.15.0->tfx[kfp]==1.15.0)\n",
      "  Downloading pickleshare-0.7.5-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: traitlets>=4.2 in /opt/conda/lib/python3.10/site-packages (from ipython<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx==1.15.0->tfx[kfp]==1.15.0) (5.14.3)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from ipython<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx==1.15.0->tfx[kfp]==1.15.0) (3.0.50)\n",
      "Requirement already satisfied: pygments in /opt/conda/lib/python3.10/site-packages (from ipython<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx==1.15.0->tfx[kfp]==1.15.0) (2.19.1)\n",
      "Collecting backcall (from ipython<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx==1.15.0->tfx[kfp]==1.15.0)\n",
      "  Downloading backcall-0.2.0-py2.py3-none-any.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: matplotlib-inline in /opt/conda/lib/python3.10/site-packages (from ipython<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx==1.15.0->tfx[kfp]==1.15.0) (0.1.7)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.10/site-packages (from ipython<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx==1.15.0->tfx[kfp]==1.15.0) (4.9.0)\n",
      "Requirement already satisfied: comm>=0.1.3 in /opt/conda/lib/python3.10/site-packages (from ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx==1.15.0->tfx[kfp]==1.15.0) (0.2.2)\n",
      "Requirement already satisfied: ipython-genutils~=0.2.0 in /opt/conda/lib/python3.10/site-packages (from ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx==1.15.0->tfx[kfp]==1.15.0) (0.2.0)\n",
      "Collecting widgetsnbextension~=3.6.10 (from ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx==1.15.0->tfx[kfp]==1.15.0)\n",
      "  Downloading widgetsnbextension-3.6.10-py2.py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting jupyterlab-widgets<3,>=1.0.0 (from ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx==1.15.0->tfx[kfp]==1.15.0)\n",
      "  Downloading jupyterlab_widgets-1.1.11-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/lib/python3.10/site-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx==1.15.0->tfx[kfp]==1.15.0) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /opt/conda/lib/python3.10/site-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx==1.15.0->tfx[kfp]==1.15.0) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx==1.15.0->tfx[kfp]==1.15.0) (0.22.3)\n",
      "Requirement already satisfied: pyasn1>=0.1.7 in /opt/conda/lib/python3.10/site-packages (from oauth2client>=1.4.12->google-apitools<1,>=0.5->tfx==1.15.0->tfx[kfp]==1.15.0) (0.6.1)\n",
      "Collecting dnspython<3.0.0,>=1.16.0 (from pymongo<5.0.0,>=3.8.0->apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx==1.15.0->tfx[kfp]==1.15.0)\n",
      "  Downloading dnspython-2.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: async-timeout>=4.0.3 in /opt/conda/lib/python3.10/site-packages (from redis<6,>=5.0.0->apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx==1.15.0->tfx[kfp]==1.15.0) (5.0.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.24.0->apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx==1.15.0->tfx[kfp]==1.15.0) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.24.0->apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx==1.15.0->tfx[kfp]==1.15.0) (3.10)\n",
      "Collecting nltk (from rouge-score<2,>=0.1.2->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx==1.15.0->tfx[kfp]==1.15.0)\n",
      "  Downloading nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting portalocker (from sacrebleu<4,>=2.3->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx==1.15.0->tfx[kfp]==1.15.0)\n",
      "  Downloading portalocker-3.1.1-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: colorama in /opt/conda/lib/python3.10/site-packages (from sacrebleu<4,>=2.3->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx==1.15.0->tfx[kfp]==1.15.0) (0.4.6)\n",
      "Collecting lxml (from sacrebleu<4,>=2.3->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx==1.15.0->tfx[kfp]==1.15.0)\n",
      "  Downloading lxml-5.3.1-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tfx==1.15.0->tfx[kfp]==1.15.0) (1.2.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tfx==1.15.0->tfx[kfp]==1.15.0) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tfx==1.15.0->tfx[kfp]==1.15.0) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tfx==1.15.0->tfx[kfp]==1.15.0) (3.1.3)\n",
      "Collecting shellingham>=1.3.0 (from typer<1.0,>=0.3.2->kfp<2,>=1.8.14->tfx[kfp]==1.15.0)\n",
      "  Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: rich>=10.11.0 in /opt/conda/lib/python3.10/site-packages (from typer<1.0,>=0.3.2->kfp<2,>=1.8.14->tfx[kfp]==1.15.0) (13.9.4)\n",
      "Requirement already satisfied: keyring in /opt/conda/lib/python3.10/site-packages (from keyrings.google-artifactregistry-auth->apache-beam[gcp]<3,>=2.47->tfx==1.15.0->tfx[kfp]==1.15.0) (25.6.0)\n",
      "Requirement already satisfied: pluggy in /opt/conda/lib/python3.10/site-packages (from keyrings.google-artifactregistry-auth->apache-beam[gcp]<3,>=2.47->tfx==1.15.0->tfx[kfp]==1.15.0) (1.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib->kubernetes<13,>=10.0.1->tfx==1.15.0->tfx[kfp]==1.15.0) (3.2.2)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /opt/conda/lib/python3.10/site-packages (from jedi>=0.16->ipython<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx==1.15.0->tfx[kfp]==1.15.0) (0.8.4)\n",
      "Requirement already satisfied: importlib-metadata<=8.4.0,>=6.0 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-api>=1.27.0->google-cloud-pubsub<3,>=2.1.0->apache-beam[gcp]<3,>=2.47->tfx==1.15.0->tfx[kfp]==1.15.0) (8.4.0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.48b0 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-sdk>=1.27.0->google-cloud-pubsub<3,>=2.1.0->apache-beam[gcp]<3,>=2.47->tfx==1.15.0->tfx[kfp]==1.15.0) (0.48b0)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.10/site-packages (from pexpect>4.3->ipython<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx==1.15.0->tfx[kfp]==1.15.0) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.10/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx==1.15.0->tfx[kfp]==1.15.0) (0.2.13)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0,>=0.3.2->kfp<2,>=1.8.14->tfx[kfp]==1.15.0) (3.0.0)\n",
      "Requirement already satisfied: notebook>=4.4.1 in /opt/conda/lib/python3.10/site-packages (from widgetsnbextension~=3.6.10->ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx==1.15.0->tfx[kfp]==1.15.0) (6.5.7)\n",
      "Requirement already satisfied: SecretStorage>=3.2 in /opt/conda/lib/python3.10/site-packages (from keyring->keyrings.google-artifactregistry-auth->apache-beam[gcp]<3,>=2.47->tfx==1.15.0->tfx[kfp]==1.15.0) (3.3.3)\n",
      "Requirement already satisfied: jeepney>=0.4.2 in /opt/conda/lib/python3.10/site-packages (from keyring->keyrings.google-artifactregistry-auth->apache-beam[gcp]<3,>=2.47->tfx==1.15.0->tfx[kfp]==1.15.0) (0.8.0)\n",
      "Requirement already satisfied: jaraco.classes in /opt/conda/lib/python3.10/site-packages (from keyring->keyrings.google-artifactregistry-auth->apache-beam[gcp]<3,>=2.47->tfx==1.15.0->tfx[kfp]==1.15.0) (3.4.0)\n",
      "Requirement already satisfied: jaraco.functools in /opt/conda/lib/python3.10/site-packages (from keyring->keyrings.google-artifactregistry-auth->apache-beam[gcp]<3,>=2.47->tfx==1.15.0->tfx[kfp]==1.15.0) (4.1.0)\n",
      "Requirement already satisfied: jaraco.context in /opt/conda/lib/python3.10/site-packages (from keyring->keyrings.google-artifactregistry-auth->apache-beam[gcp]<3,>=2.47->tfx==1.15.0->tfx[kfp]==1.15.0) (6.0.1)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from nltk->rouge-score<2,>=0.1.2->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx==1.15.0->tfx[kfp]==1.15.0) (4.67.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.10/site-packages (from importlib-metadata<=8.4.0,>=6.0->opentelemetry-api>=1.27.0->google-cloud-pubsub<3,>=2.1.0->apache-beam[gcp]<3,>=2.47->tfx==1.15.0->tfx[kfp]==1.15.0) (3.21.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.3.2->kfp<2,>=1.8.14->tfx[kfp]==1.15.0) (0.1.2)\n",
      "Requirement already satisfied: tornado>=6.1 in /opt/conda/lib/python3.10/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx==1.15.0->tfx[kfp]==1.15.0) (6.4.2)\n",
      "Requirement already satisfied: pyzmq>=17 in /opt/conda/lib/python3.10/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx==1.15.0->tfx[kfp]==1.15.0) (26.2.1)\n",
      "Requirement already satisfied: argon2-cffi in /opt/conda/lib/python3.10/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx==1.15.0->tfx[kfp]==1.15.0) (23.1.0)\n",
      "Requirement already satisfied: jupyter-core>=4.6.1 in /opt/conda/lib/python3.10/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx==1.15.0->tfx[kfp]==1.15.0) (5.7.2)\n",
      "Requirement already satisfied: jupyter-client<8,>=5.3.4 in /opt/conda/lib/python3.10/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx==1.15.0->tfx[kfp]==1.15.0) (7.4.9)\n",
      "Requirement already satisfied: nbformat in /opt/conda/lib/python3.10/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx==1.15.0->tfx[kfp]==1.15.0) (5.10.4)\n",
      "Requirement already satisfied: nbconvert>=5 in /opt/conda/lib/python3.10/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx==1.15.0->tfx[kfp]==1.15.0) (7.16.6)\n",
      "Requirement already satisfied: nest-asyncio>=1.5 in /opt/conda/lib/python3.10/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx==1.15.0->tfx[kfp]==1.15.0) (1.6.0)\n",
      "Requirement already satisfied: ipykernel in /opt/conda/lib/python3.10/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx==1.15.0->tfx[kfp]==1.15.0) (6.29.5)\n",
      "Requirement already satisfied: Send2Trash>=1.8.0 in /opt/conda/lib/python3.10/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx==1.15.0->tfx[kfp]==1.15.0) (1.8.3)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /opt/conda/lib/python3.10/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx==1.15.0->tfx[kfp]==1.15.0) (0.18.1)\n",
      "Requirement already satisfied: prometheus-client in /opt/conda/lib/python3.10/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx==1.15.0->tfx[kfp]==1.15.0) (0.21.1)\n",
      "Requirement already satisfied: nbclassic>=0.4.7 in /opt/conda/lib/python3.10/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx==1.15.0->tfx[kfp]==1.15.0) (1.2.0)\n",
      "Requirement already satisfied: cryptography>=2.0 in /opt/conda/lib/python3.10/site-packages (from SecretStorage>=3.2->keyring->keyrings.google-artifactregistry-auth->apache-beam[gcp]<3,>=2.47->tfx==1.15.0->tfx[kfp]==1.15.0) (44.0.0)\n",
      "Requirement already satisfied: more-itertools in /opt/conda/lib/python3.10/site-packages (from jaraco.classes->keyring->keyrings.google-artifactregistry-auth->apache-beam[gcp]<3,>=2.47->tfx==1.15.0->tfx[kfp]==1.15.0) (10.6.0)\n",
      "Requirement already satisfied: backports.tarfile in /opt/conda/lib/python3.10/site-packages (from jaraco.context->keyring->keyrings.google-artifactregistry-auth->apache-beam[gcp]<3,>=2.47->tfx==1.15.0->tfx[kfp]==1.15.0) (1.2.0)\n",
      "Requirement already satisfied: cffi>=1.12 in /opt/conda/lib/python3.10/site-packages (from cryptography>=2.0->SecretStorage>=3.2->keyring->keyrings.google-artifactregistry-auth->apache-beam[gcp]<3,>=2.47->tfx==1.15.0->tfx[kfp]==1.15.0) (1.17.1)\n",
      "Requirement already satisfied: entrypoints in /opt/conda/lib/python3.10/site-packages (from jupyter-client<8,>=5.3.4->notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx==1.15.0->tfx[kfp]==1.15.0) (0.4)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /opt/conda/lib/python3.10/site-packages (from jupyter-core>=4.6.1->notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx==1.15.0->tfx[kfp]==1.15.0) (4.3.6)\n",
      "Requirement already satisfied: notebook-shim>=0.2.3 in /opt/conda/lib/python3.10/site-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx==1.15.0->tfx[kfp]==1.15.0) (0.2.4)\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.10/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx==1.15.0->tfx[kfp]==1.15.0) (4.13.3)\n",
      "Requirement already satisfied: bleach!=5.0.0 in /opt/conda/lib/python3.10/site-packages (from bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx==1.15.0->tfx[kfp]==1.15.0) (6.2.0)\n",
      "Requirement already satisfied: defusedxml in /opt/conda/lib/python3.10/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx==1.15.0->tfx[kfp]==1.15.0) (0.7.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in /opt/conda/lib/python3.10/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx==1.15.0->tfx[kfp]==1.15.0) (0.3.0)\n",
      "Requirement already satisfied: mistune<4,>=2.0.3 in /opt/conda/lib/python3.10/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx==1.15.0->tfx[kfp]==1.15.0) (3.1.1)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in /opt/conda/lib/python3.10/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx==1.15.0->tfx[kfp]==1.15.0) (0.10.2)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /opt/conda/lib/python3.10/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx==1.15.0->tfx[kfp]==1.15.0) (1.5.1)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in /opt/conda/lib/python3.10/site-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx==1.15.0->tfx[kfp]==1.15.0) (2.21.1)\n",
      "Requirement already satisfied: argon2-cffi-bindings in /opt/conda/lib/python3.10/site-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx==1.15.0->tfx[kfp]==1.15.0) (21.2.0)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in /opt/conda/lib/python3.10/site-packages (from ipykernel->notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx==1.15.0->tfx[kfp]==1.15.0) (1.8.12)\n",
      "Requirement already satisfied: webencodings in /opt/conda/lib/python3.10/site-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx==1.15.0->tfx[kfp]==1.15.0) (0.5.1)\n",
      "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx==1.15.0->tfx[kfp]==1.15.0) (1.4.0)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.10/site-packages (from cffi>=1.12->cryptography>=2.0->SecretStorage>=3.2->keyring->keyrings.google-artifactregistry-auth->apache-beam[gcp]<3,>=2.47->tfx==1.15.0->tfx[kfp]==1.15.0) (2.22)\n",
      "Requirement already satisfied: jupyter-server<3,>=1.8 in /opt/conda/lib/python3.10/site-packages (from notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx==1.15.0->tfx[kfp]==1.15.0) (2.15.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx==1.15.0->tfx[kfp]==1.15.0) (2.6)\n",
      "Requirement already satisfied: anyio>=3.1.0 in /opt/conda/lib/python3.10/site-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx==1.15.0->tfx[kfp]==1.15.0) (4.8.0)\n",
      "Requirement already satisfied: jupyter-events>=0.11.0 in /opt/conda/lib/python3.10/site-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx==1.15.0->tfx[kfp]==1.15.0) (0.12.0)\n",
      "Requirement already satisfied: jupyter-server-terminals>=0.4.4 in /opt/conda/lib/python3.10/site-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx==1.15.0->tfx[kfp]==1.15.0) (0.5.3)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx==1.15.0->tfx[kfp]==1.15.0) (1.2.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.10/site-packages (from anyio>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx==1.15.0->tfx[kfp]==1.15.0) (1.3.1)\n",
      "Requirement already satisfied: python-json-logger>=2.0.4 in /opt/conda/lib/python3.10/site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx==1.15.0->tfx[kfp]==1.15.0) (3.2.1)\n",
      "Requirement already satisfied: rfc3339-validator in /opt/conda/lib/python3.10/site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx==1.15.0->tfx[kfp]==1.15.0) (0.1.4)\n",
      "Requirement already satisfied: rfc3986-validator>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx==1.15.0->tfx[kfp]==1.15.0) (0.1.1)\n",
      "Requirement already satisfied: fqdn in /opt/conda/lib/python3.10/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx==1.15.0->tfx[kfp]==1.15.0) (1.5.1)\n",
      "Requirement already satisfied: isoduration in /opt/conda/lib/python3.10/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx==1.15.0->tfx[kfp]==1.15.0) (20.11.0)\n",
      "Requirement already satisfied: jsonpointer>1.13 in /opt/conda/lib/python3.10/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx==1.15.0->tfx[kfp]==1.15.0) (3.0.0)\n",
      "Requirement already satisfied: uri-template in /opt/conda/lib/python3.10/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx==1.15.0->tfx[kfp]==1.15.0) (1.3.0)\n",
      "Requirement already satisfied: webcolors>=24.6.0 in /opt/conda/lib/python3.10/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx==1.15.0->tfx[kfp]==1.15.0) (24.11.1)\n",
      "Requirement already satisfied: arrow>=0.15.0 in /opt/conda/lib/python3.10/site-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx==1.15.0->tfx[kfp]==1.15.0) (1.3.0)\n",
      "Requirement already satisfied: types-python-dateutil>=2.8.10 in /opt/conda/lib/python3.10/site-packages (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx==1.15.0->tfx[kfp]==1.15.0) (2.9.0.20241206)\n",
      "Downloading tfx-1.15.0-py3-none-any.whl (2.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m53.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ml_pipelines_sdk-1.15.0-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m83.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading absl_py-1.4.0-py3-none-any.whl (126 kB)\n",
      "Downloading apache_beam-2.63.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.2/16.2 MB\u001b[0m \u001b[31m63.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading attrs-23.2.0-py3-none-any.whl (60 kB)\n",
      "Downloading docker-4.4.4-py2.py3-none-any.whl (147 kB)\n",
      "Downloading google_api_core-2.24.2-py3-none-any.whl (160 kB)\n",
      "Downloading google_api_python_client-1.12.11-py2.py3-none-any.whl (62 kB)\n",
      "Downloading grpcio-1.65.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m65.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading keras_tuner-1.4.7-py3-none-any.whl (129 kB)\n",
      "Downloading kfp_pipeline_spec-0.1.16-py3-none-any.whl (19 kB)\n",
      "Downloading kubernetes-12.0.1-py2.py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m79.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ml_metadata-1.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m60.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading portpicker-1.6.0-py3-none-any.whl (16 kB)\n",
      "Downloading pyarrow-10.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (35.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.9/35.9 MB\u001b[0m \u001b[31m81.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading scipy-1.12.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.4/38.4 MB\u001b[0m \u001b[31m86.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tensorflow_data_validation-1.15.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.0/19.0 MB\u001b[0m \u001b[31m84.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tensorflow_hub-0.15.0-py2.py3-none-any.whl (85 kB)\n",
      "Downloading tensorflow_model_analysis-0.46.0-py3-none-any.whl (1.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m84.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorflow_serving_api-2.15.1-py2.py3-none-any.whl (26 kB)\n",
      "Downloading tensorflow_transform-1.15.0-py3-none-any.whl (451 kB)\n",
      "Downloading tfx_bsl-1.15.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (22.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.5/22.5 MB\u001b[0m \u001b[31m83.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading cloudpickle-2.2.1-py3-none-any.whl (25 kB)\n",
      "Downloading fastavro-1.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m35.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fasteners-0.19-py3-none-any.whl (18 kB)\n",
      "Downloading google_cloud_bigtable-2.29.0-py2.py3-none-any.whl (445 kB)\n",
      "Downloading google_cloud_datastore-2.20.2-py2.py3-none-any.whl (197 kB)\n",
      "Downloading google_cloud_dlp-3.28.1-py3-none-any.whl (212 kB)\n",
      "Downloading google_cloud_pubsub-2.28.0-py2.py3-none-any.whl (301 kB)\n",
      "Downloading google_cloud_pubsublite-1.12.0-py2.py3-none-any.whl (322 kB)\n",
      "Downloading google_cloud_recommendations_ai-0.10.17-py3-none-any.whl (211 kB)\n",
      "Downloading google_cloud_spanner-3.53.0-py2.py3-none-any.whl (483 kB)\n",
      "Downloading google_cloud_storage-2.19.0-py2.py3-none-any.whl (131 kB)\n",
      "Downloading google_cloud_videointelligence-2.16.1-py3-none-any.whl (274 kB)\n",
      "Downloading google_cloud_vision-3.10.1-py3-none-any.whl (526 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m526.1/526.1 kB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ipython-7.34.0-py3-none-any.whl (793 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m793.8/793.8 kB\u001b[0m \u001b[31m36.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ipywidgets-7.8.5-py2.py3-none-any.whl (124 kB)\n",
      "Downloading jsonpickle-3.4.2-py3-none-any.whl (46 kB)\n",
      "Downloading objsize-0.7.1-py3-none-any.whl (11 kB)\n",
      "Downloading orjson-3.10.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
      "Downloading pandas-1.5.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m77.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydantic-1.10.21-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m100.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydot-1.4.2-py2.py3-none-any.whl (21 kB)\n",
      "Downloading pymongo-4.11.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m55.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading redis-5.2.1-py3-none-any.whl (261 kB)\n",
      "Downloading regex-2024.11.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (781 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.7/781.7 kB\u001b[0m \u001b[31m41.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading sacrebleu-2.5.1-py3-none-any.whl (104 kB)\n",
      "Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
      "Downloading strip_hints-0.1.13-py3-none-any.whl (23 kB)\n",
      "Downloading tensorflow_metadata-1.15.0-py3-none-any.whl (28 kB)\n",
      "Downloading typer-0.15.2-py3-none-any.whl (45 kB)\n",
      "Downloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
      "Downloading dnspython-2.7.0-py3-none-any.whl (313 kB)\n",
      "Downloading grpc_interceptor-0.15.4-py3-none-any.whl (20 kB)\n",
      "Downloading jupyterlab_widgets-1.1.11-py3-none-any.whl (246 kB)\n",
      "Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Downloading widgetsnbextension-3.6.10-py2.py3-none-any.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m73.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading backcall-0.2.0-py2.py3-none-any.whl (11 kB)\n",
      "Downloading lxml-5.3.1-cp310-cp310-manylinux_2_28_x86_64.whl (5.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m74.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m68.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pickleshare-0.7.5-py2.py3-none-any.whl (6.9 kB)\n",
      "Downloading portalocker-3.1.1-py3-none-any.whl (19 kB)\n",
      "Building wheels for collected packages: google-apitools, kfp, crcmod, dill, fire, hdfs, kfp-server-api, pyfarmhash, rouge-score, docopt\n",
      "  Building wheel for google-apitools (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for google-apitools: filename=google_apitools-0.5.31-py3-none-any.whl size=131078 sha256=3cba91ffa12452d78f79cc05f473a85d37547c29e0fad4a8f008ff5917e473b8\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/04/b7/e0/9712f8c23a5da3d9d16fb88216b897bf60e85b12f5470f26ee\n",
      "  Building wheel for kfp (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for kfp: filename=kfp-1.8.22-py3-none-any.whl size=427024 sha256=6706dfe9c434824e40a35c6ddc87718d4517e39a14624eedaf1d71f1df744744\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/74/c0/fc/bf0ab209fd6ae814d7efbc821076e948c3e4884f846583ab58\n",
      "  Building wheel for crcmod (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for crcmod: filename=crcmod-1.7-cp310-cp310-linux_x86_64.whl size=23137 sha256=49d6c991ae61421ec7aab0050aae831b57abf4ebf0b67f9e7bf4e0ed81930558\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/85/4c/07/72215c529bd59d67e3dac29711d7aba1b692f543c808ba9e86\n",
      "  Building wheel for dill (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for dill: filename=dill-0.3.1.1-py3-none-any.whl size=78604 sha256=f0b9bbfcf16c284c03b2f2dd741cd26b6a14479b63789787cce8e2cce9e17860\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/ea/e2/86/64980d90e297e7bf2ce588c2b96e818f5399c515c4bb8a7e4f\n",
      "  Building wheel for fire (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for fire: filename=fire-0.7.0-py3-none-any.whl size=114298 sha256=6075634ea3a8fde7b1c2694696de07c1d20c37ad6ff668979045a4c7603995f4\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/19/39/2f/2d3cadc408a8804103f1c34ddd4b9f6a93497b11fa96fe738e\n",
      "  Building wheel for hdfs (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for hdfs: filename=hdfs-2.7.3-py3-none-any.whl size=34383 sha256=c02f6e6961104de4004389c71b3ab8cd87efb99215b3e378620d2c495f4a01d0\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/e5/8d/b6/99c1c0a3ac5788c866b0ecd3f48b0134a5910e6ed26011800b\n",
      "  Building wheel for kfp-server-api (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for kfp-server-api: filename=kfp_server_api-1.8.5-py3-none-any.whl size=99744 sha256=a7fe430de27c016b89a5bc3cefbbeaf01ba7be6d87ee371e0fc125f164e3aa77\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/c5/97/d5/e8a0f596dc85f5cfe383c800fbf3e29a99853bb54e01f26fca\n",
      "  Building wheel for pyfarmhash (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pyfarmhash: filename=pyfarmhash-0.3.2-cp310-cp310-linux_x86_64.whl size=13903 sha256=9a53cb777bd5ebd0cc7694447619229694d5ed6ecf1002fee896d63a28180dbe\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/e0/08/da/f66b1f3258fe3f1e767b2136c5444dbfa9fa3f7944cc5e1983\n",
      "  Building wheel for rouge-score (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24986 sha256=3aebcbd9f40e2d6120b635559efd21181bb25adad1f7ef003fe0ce16d169fc13\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n",
      "  Building wheel for docopt (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13749 sha256=729ff9965c019411a385c37e688790e8eadea913da927a66bb8aec464adf36f9\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/fc/ab/d4/5da2067ac95b36618c629a5f93f809425700506f72c9732fac\n",
      "Successfully built google-apitools kfp crcmod dill fire hdfs kfp-server-api pyfarmhash rouge-score docopt\n",
      "Installing collected packages: sortedcontainers, pyfarmhash, pickleshare, kt-legacy, docopt, crcmod, backcall, tensorflow-hub, strip-hints, shellingham, scipy, regex, redis, pydot, pydantic, pyarrow, portpicker, portalocker, orjson, objsize, lxml, kfp-pipeline-spec, jupyterlab-widgets, jsonpickle, grpcio, fire, fasteners, fastavro, dnspython, dill, cloudpickle, attrs, absl-py, tensorflow-metadata, sacrebleu, pymongo, pandas, nltk, ml-metadata, kfp-server-api, keras-tuner, ipython, hdfs, grpc-interceptor, docker, typer, rouge-score, kubernetes, google-apitools, google-api-core, google-api-python-client, ml-pipelines-sdk, google-cloud-vision, google-cloud-videointelligence, google-cloud-storage, google-cloud-spanner, google-cloud-recommendations-ai, google-cloud-pubsub, google-cloud-dlp, google-cloud-datastore, google-cloud-bigtable, apache-beam, tensorflow-serving-api, kfp, google-cloud-pubsublite, tfx-bsl, tensorflow-transform, tensorflow-data-validation, widgetsnbextension, ipywidgets, tensorflow-model-analysis, tfx\n",
      "  Attempting uninstall: scipy\n",
      "    Found existing installation: scipy 1.15.1\n",
      "    Uninstalling scipy-1.15.1:\n",
      "      Successfully uninstalled scipy-1.15.1\n",
      "  Attempting uninstall: pydantic\n",
      "    Found existing installation: pydantic 2.10.6\n",
      "    Uninstalling pydantic-2.10.6:\n",
      "      Successfully uninstalled pydantic-2.10.6\n",
      "  Attempting uninstall: pyarrow\n",
      "    Found existing installation: pyarrow 15.0.2\n",
      "    Uninstalling pyarrow-15.0.2:\n",
      "      Successfully uninstalled pyarrow-15.0.2\n",
      "  Attempting uninstall: kfp-pipeline-spec\n",
      "    Found existing installation: kfp-pipeline-spec 0.2.2\n",
      "    Uninstalling kfp-pipeline-spec-0.2.2:\n",
      "      Successfully uninstalled kfp-pipeline-spec-0.2.2\n",
      "  Attempting uninstall: jupyterlab-widgets\n",
      "    Found existing installation: jupyterlab_widgets 3.0.13\n",
      "    Uninstalling jupyterlab_widgets-3.0.13:\n",
      "      Successfully uninstalled jupyterlab_widgets-3.0.13\n",
      "  Attempting uninstall: grpcio\n",
      "    Found existing installation: grpcio 1.70.0\n",
      "    Uninstalling grpcio-1.70.0:\n",
      "      Successfully uninstalled grpcio-1.70.0\n",
      "\u001b[33m  WARNING: Failed to remove contents in a temporary directory '/opt/conda/lib/python3.10/site-packages/~rpc'.\n",
      "  You can safely remove it manually.\u001b[0m\u001b[33m\n",
      "\u001b[0m  Attempting uninstall: cloudpickle\n",
      "    Found existing installation: cloudpickle 3.1.1\n",
      "    Uninstalling cloudpickle-3.1.1:\n",
      "      Successfully uninstalled cloudpickle-3.1.1\n",
      "  Attempting uninstall: attrs\n",
      "    Found existing installation: attrs 25.1.0\n",
      "    Uninstalling attrs-25.1.0:\n",
      "      Successfully uninstalled attrs-25.1.0\n",
      "  Attempting uninstall: absl-py\n",
      "    Found existing installation: absl-py 2.1.0\n",
      "    Uninstalling absl-py-2.1.0:\n",
      "      Successfully uninstalled absl-py-2.1.0\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 2.2.3\n",
      "    Uninstalling pandas-2.2.3:\n",
      "      Successfully uninstalled pandas-2.2.3\n",
      "  Attempting uninstall: kfp-server-api\n",
      "    Found existing installation: kfp-server-api 2.0.5\n",
      "    Uninstalling kfp-server-api-2.0.5:\n",
      "      Successfully uninstalled kfp-server-api-2.0.5\n",
      "  Attempting uninstall: ipython\n",
      "    Found existing installation: ipython 8.21.0\n",
      "    Uninstalling ipython-8.21.0:\n",
      "      Successfully uninstalled ipython-8.21.0\n",
      "  Attempting uninstall: docker\n",
      "    Found existing installation: docker 7.1.0\n",
      "    Uninstalling docker-7.1.0:\n",
      "      Successfully uninstalled docker-7.1.0\n",
      "  Attempting uninstall: kubernetes\n",
      "    Found existing installation: kubernetes 26.1.0\n",
      "    Uninstalling kubernetes-26.1.0:\n",
      "      Successfully uninstalled kubernetes-26.1.0\n",
      "  Attempting uninstall: google-api-core\n",
      "    Found existing installation: google-api-core 1.34.1\n",
      "    Uninstalling google-api-core-1.34.1:\n",
      "      Successfully uninstalled google-api-core-1.34.1\n",
      "\u001b[33m  WARNING: Failed to remove contents in a temporary directory '/opt/conda/lib/python3.10/site-packages/google/~pi_core'.\n",
      "  You can safely remove it manually.\u001b[0m\u001b[33m\n",
      "\u001b[0m  Attempting uninstall: google-api-python-client\n",
      "    Found existing installation: google-api-python-client 1.8.0\n",
      "    Uninstalling google-api-python-client-1.8.0:\n",
      "      Successfully uninstalled google-api-python-client-1.8.0\n",
      "  Attempting uninstall: google-cloud-storage\n",
      "    Found existing installation: google-cloud-storage 2.14.0\n",
      "    Uninstalling google-cloud-storage-2.14.0:\n",
      "      Successfully uninstalled google-cloud-storage-2.14.0\n",
      "  Attempting uninstall: google-cloud-datastore\n",
      "    Found existing installation: google-cloud-datastore 1.15.5\n",
      "    Uninstalling google-cloud-datastore-1.15.5:\n",
      "      Successfully uninstalled google-cloud-datastore-1.15.5\n",
      "\u001b[33m  WARNING: Failed to remove contents in a temporary directory '/opt/conda/lib/python3.10/site-packages/google/cloud/~atastore'.\n",
      "  You can safely remove it manually.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: Failed to remove contents in a temporary directory '/opt/conda/lib/python3.10/site-packages/google/cloud/~atastore_v1'.\n",
      "  You can safely remove it manually.\u001b[0m\u001b[33m\n",
      "\u001b[0m  Attempting uninstall: kfp\n",
      "    Found existing installation: kfp 2.5.0\n",
      "    Uninstalling kfp-2.5.0:\n",
      "      Successfully uninstalled kfp-2.5.0\n",
      "  Attempting uninstall: widgetsnbextension\n",
      "    Found existing installation: widgetsnbextension 4.0.13\n",
      "    Uninstalling widgetsnbextension-4.0.13:\n",
      "      Successfully uninstalled widgetsnbextension-4.0.13\n",
      "  Attempting uninstall: ipywidgets\n",
      "    Found existing installation: ipywidgets 8.1.5\n",
      "    Uninstalling ipywidgets-8.1.5:\n",
      "      Successfully uninstalled ipywidgets-8.1.5\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "cloud-tpu-client 0.10 requires google-api-python-client==1.8.0, but you have google-api-python-client 1.12.11 which is incompatible.\n",
      "visions 0.7.6 requires pandas>=2.0.0, but you have pandas 1.5.3 which is incompatible.\n",
      "ydata-profiling 4.12.2 requires pydantic>=2, but you have pydantic 1.10.21 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed absl-py-1.4.0 apache-beam-2.63.0 attrs-23.2.0 backcall-0.2.0 cloudpickle-2.2.1 crcmod-1.7 dill-0.3.1.1 dnspython-2.7.0 docker-4.4.4 docopt-0.6.2 fastavro-1.10.0 fasteners-0.19 fire-0.7.0 google-api-core-2.24.2 google-api-python-client-1.12.11 google-apitools-0.5.31 google-cloud-bigtable-2.29.0 google-cloud-datastore-2.20.2 google-cloud-dlp-3.28.1 google-cloud-pubsub-2.28.0 google-cloud-pubsublite-1.12.0 google-cloud-recommendations-ai-0.10.17 google-cloud-spanner-3.53.0 google-cloud-storage-2.19.0 google-cloud-videointelligence-2.16.1 google-cloud-vision-3.10.1 grpc-interceptor-0.15.4 grpcio-1.65.5 hdfs-2.7.3 ipython-7.34.0 ipywidgets-7.8.5 jsonpickle-3.4.2 jupyterlab-widgets-1.1.11 keras-tuner-1.4.7 kfp-1.8.22 kfp-pipeline-spec-0.1.16 kfp-server-api-1.8.5 kt-legacy-1.0.5 kubernetes-12.0.1 lxml-5.3.1 ml-metadata-1.15.0 ml-pipelines-sdk-1.15.0 nltk-3.9.1 objsize-0.7.1 orjson-3.10.15 pandas-1.5.3 pickleshare-0.7.5 portalocker-3.1.1 portpicker-1.6.0 pyarrow-10.0.1 pydantic-1.10.21 pydot-1.4.2 pyfarmhash-0.3.2 pymongo-4.11.2 redis-5.2.1 regex-2024.11.6 rouge-score-0.1.2 sacrebleu-2.5.1 scipy-1.12.0 shellingham-1.5.4 sortedcontainers-2.4.0 strip-hints-0.1.13 tensorflow-data-validation-1.15.1 tensorflow-hub-0.15.0 tensorflow-metadata-1.15.0 tensorflow-model-analysis-0.46.0 tensorflow-serving-api-2.15.1 tensorflow-transform-1.15.0 tfx-1.15.0 tfx-bsl-1.15.1 typer-0.15.2 widgetsnbextension-3.6.10\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade pip \n",
    "%pip uninstall tensorflow tensorflow-tensorboard tensorflow-io tensorflow-cloud -y \n",
    "%pip install tensorflow==2.15.1\n",
    "%pip uninstall tfx -y \n",
    "%pip install -U \"tfx[kfp]==1.15.0\"\n",
    "\n",
    "# You may see package dependency errors in the output below. You may ignore these to run the cells of this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EwT0nov5QO1M"
   },
   "source": [
    "#### Restart the runtime\n",
    "\n",
    "Restart the runtime to ensure the following cells use the updated versions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-CRyIL4LVDlQ"
   },
   "source": [
    "You can restart the runtime with following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "KHTSzMygoBF6",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# docs_infra: no_execute\n",
    "import sys\n",
    "if not 'google.colab' in sys.modules:\n",
    "  # Automatically restart kernel after installs\n",
    "  import IPython\n",
    "  app = IPython.Application.instance()\n",
    "  app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3_SveIKxaENu"
   },
   "source": [
    "Check the package versions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Xd-iP9wEaENu",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-18 10:25:06.033692: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-03-18 10:25:06.595329: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-03-18 10:25:06.595394: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-03-18 10:25:06.601895: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-18 10:25:06.628804: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-03-18 10:25:06.631982: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.15.1\n",
      "TFX version: 1.15.0\n",
      "KFP version: 1.8.22\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print('TensorFlow version: {}'.format(tf.__version__))\n",
    "from tfx import v1 as tfx\n",
    "print('TFX version: {}'.format(tfx.__version__))\n",
    "import kfp\n",
    "print('KFP version: {}'.format(kfp.__version__))\n",
    "\n",
    "# You may see a WARNING issued. You can safely ignore this until the TFX and KFP versions are displayed in the cell output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aDtLdSkvqPHe"
   },
   "source": [
    "### Set up variables\n",
    "\n",
    "We will set up some variables used to customize the pipelines below. Following\n",
    "information is required:\n",
    "\n",
    "* GCP Project id. You can find your Project ID in the panel with your lab instructions.\n",
    "* GCP Region to run pipelines. For more information about the regions that\n",
    "Vertex Pipelines is available in, see the\n",
    "[Vertex AI locations guide](https://cloud.google.com/vertex-ai/docs/general/locations#feature-availability).\n",
    "* Google Cloud Storage Bucket to store pipeline outputs.\n",
    "\n",
    "**Enter required values in the cell below before running it**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "EcUseqJaE2XN",
    "tags": []
   },
   "outputs": [],
   "source": [
    "GOOGLE_CLOUD_PROJECT = 'qwiklabs-gcp-03-a80d0796ed0b'    \n",
    "GOOGLE_CLOUD_REGION = 'us-central1'     \n",
    "GCS_BUCKET_NAME = GOOGLE_CLOUD_PROJECT + '-gcs'\n",
    "\n",
    "if not (GOOGLE_CLOUD_PROJECT and GOOGLE_CLOUD_REGION and GCS_BUCKET_NAME):\n",
    "    from absl import logging\n",
    "    logging.error('Please set all required parameters.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GAaCPLjgiJrO"
   },
   "source": [
    "Set `gcloud` to use your project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "VkWdxe4TXRHk",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated property [core/project].\n"
     ]
    }
   ],
   "source": [
    "!gcloud config set project {GOOGLE_CLOUD_PROJECT}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "CPN6UL5CazNy",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PIPELINE_ROOT: gs://qwiklabs-gcp-03-a80d0796ed0b-gcs/pipeline_root/penguin-vertex-pipelines\n",
      "MODULE_ROOT: gs://qwiklabs-gcp-03-a80d0796ed0b-gcs/pipeline_module/penguin-vertex-pipelines\n",
      "DATA_ROOT: gs://qwiklabs-gcp-03-a80d0796ed0b-gcs/data/penguin-vertex-pipelines\n",
      "SERVING_MODEL_DIR: gs://qwiklabs-gcp-03-a80d0796ed0b-gcs/serving_model/penguin-vertex-pipelines\n"
     ]
    }
   ],
   "source": [
    "PIPELINE_NAME = 'penguin-vertex-pipelines'\n",
    "\n",
    "# Path to various pipeline artifact.\n",
    "PIPELINE_ROOT = 'gs://{}/pipeline_root/{}'.format(\n",
    "    GCS_BUCKET_NAME, PIPELINE_NAME)\n",
    "\n",
    "# Paths for users' Python module.\n",
    "MODULE_ROOT = 'gs://{}/pipeline_module/{}'.format(\n",
    "    GCS_BUCKET_NAME, PIPELINE_NAME)\n",
    "\n",
    "# Paths for input data.\n",
    "DATA_ROOT = 'gs://{}/data/{}'.format(GCS_BUCKET_NAME, PIPELINE_NAME)\n",
    "\n",
    "# This is the path where your model will be pushed for serving.\n",
    "SERVING_MODEL_DIR = 'gs://{}/serving_model/{}'.format(GCS_BUCKET_NAME, PIPELINE_NAME)\n",
    "\n",
    "print('PIPELINE_ROOT: {}'.format(PIPELINE_ROOT))\n",
    "print('MODULE_ROOT: {}'.format(MODULE_ROOT))\n",
    "print('DATA_ROOT: {}'.format(DATA_ROOT))\n",
    "print('SERVING_MODEL_DIR: {}'.format(SERVING_MODEL_DIR))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8F2SRwRLSYGa"
   },
   "source": [
    "### Prepare example data\n",
    "The dataset we are using is the\n",
    "[Palmer Penguins dataset](https://allisonhorst.github.io/palmerpenguins/articles/intro.html).\n",
    "\n",
    "There are four numeric features in this dataset:\n",
    "\n",
    "* culmen_length_mm\n",
    "* culmen_depth_mm\n",
    "* flipper_length_mm\n",
    "* body_mass_g\n",
    "\n",
    "All features were already normalized\n",
    "to have range [0,1]. We will build a classification model which predicts the\n",
    "`species` of penguins."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "11J7XiCq6AFP"
   },
   "source": [
    "We need to make our own copy of the dataset. Because TFX ExampleGen reads\n",
    "inputs from a directory, we need to create a directory and copy dataset to it\n",
    "on GCS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "4fxMs6u86acP",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying gs://download.tensorflow.org/data/palmer_penguins/penguins_processed.csv [Content-Type=application/octet-stream]...\n",
      "/ [1 files][ 25.0 KiB/ 25.0 KiB]                                                \n",
      "Operation completed over 1 objects/25.0 KiB.                                     \n"
     ]
    }
   ],
   "source": [
    "!gsutil cp gs://download.tensorflow.org/data/palmer_penguins/penguins_processed.csv {DATA_ROOT}/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ASpoNmxKSQjI"
   },
   "source": [
    "Take a quick look at the CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "-eSz28UDSnlG",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "species,culmen_length_mm,culmen_depth_mm,flipper_length_mm,body_mass_g\n",
      "0,0.2545454545454545,0.6666666666666666,0.15254237288135594,0.2916666666666667\n",
      "0,0.26909090909090905,0.5119047619047618,0.23728813559322035,0.3055555555555556\n",
      "0,0.29818181818181805,0.5833333333333334,0.3898305084745763,0.1527777777777778\n",
      "0,0.16727272727272732,0.7380952380952381,0.3559322033898305,0.20833333333333334\n",
      "0,0.26181818181818167,0.892857142857143,0.3050847457627119,0.2638888888888889\n",
      "0,0.24727272727272717,0.5595238095238096,0.15254237288135594,0.2569444444444444\n",
      "0,0.25818181818181823,0.773809523809524,0.3898305084745763,0.5486111111111112\n",
      "0,0.32727272727272727,0.5357142857142859,0.1694915254237288,0.1388888888888889\n",
      "0,0.23636363636363636,0.9642857142857142,0.3220338983050847,0.3055555555555556\n"
     ]
    }
   ],
   "source": [
    "!gsutil cat {DATA_ROOT}/penguins_processed.csv | head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should be able to see five values. `species` is one of 0, 1 or 2, and all other features should have values between 0 and 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nH6gizcpSwWV"
   },
   "source": [
    "## Create a pipeline\n",
    "\n",
    "TFX pipelines are defined using Python APIs. We will define a pipeline which\n",
    "consists of three components:\n",
    "\n",
    "* CsvExampleGen: Reads in data files and convert them to TFX internal format for further processing. There are multiple ExampleGens for various formats. In this tutorial, we will use CsvExampleGen which takes CSV file input.\n",
    "* Trainer: Trains an ML model. Trainer component requires a model definition code from users. You can use TensorFlow APIs to specify how to train a model and save it in a _savedmodel format.\n",
    "* Pusher: Copies the trained model outside of the TFX pipeline. Pusher component can be thought of an deployment process of the trained ML model.\n",
    "\n",
    "Our pipeline will be almost identical to a basic [TFX pipeline](https://www.tensorflow.org/tfx/tutorials/tfx/penguin_simple).\n",
    "\n",
    "The only difference is that we don't need to set `metadata_connection_config`\n",
    "which is used to locate\n",
    "[ML Metadata](https://www.tensorflow.org/tfx/guide/mlmd) database. Because\n",
    "Vertex Pipelines uses a managed metadata service, users don't need to care\n",
    "of it, and we don't need to specify the parameter.\n",
    "\n",
    "Before actually define the pipeline, we need to write a model code for the\n",
    "Trainer component first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lOjDv93eS5xV"
   },
   "source": [
    "### Write model code.\n",
    "\n",
    "We will create a simple DNN model for classification using TensorFlow Keras API. This model training code will be saved to a separate file.\n",
    "\n",
    "In this tutorial we will use __Generic Trainer__ of TFX which support Keras-based models. You need to write a Python file containing run_fn function, which is the entrypoint for the `Trainer` component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "aES7Hv5QTDK3",
    "tags": []
   },
   "outputs": [],
   "source": [
    "_trainer_module_file = 'penguin_trainer.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "Gnc67uQNTDfW",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing penguin_trainer.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {_trainer_module_file}\n",
    "\n",
    "# Copied from https://www.tensorflow.org/tfx/tutorials/tfx/penguin_simple\n",
    "\n",
    "from typing import List\n",
    "from absl import logging\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow_transform.tf_metadata import schema_utils\n",
    "\n",
    "\n",
    "from tfx import v1 as tfx\n",
    "from tfx_bsl.public import tfxio\n",
    "\n",
    "from tensorflow_metadata.proto.v0 import schema_pb2\n",
    "\n",
    "_FEATURE_KEYS = [\n",
    "    'culmen_length_mm', 'culmen_depth_mm', 'flipper_length_mm', 'body_mass_g'\n",
    "]\n",
    "_LABEL_KEY = 'species'\n",
    "\n",
    "_TRAIN_BATCH_SIZE = 20\n",
    "_EVAL_BATCH_SIZE = 10\n",
    "\n",
    "# Since we're not generating or creating a schema, we will instead create\n",
    "# a feature spec.  Since there are a fairly small number of features this is\n",
    "# manageable for this dataset.\n",
    "_FEATURE_SPEC = {\n",
    "    **{\n",
    "        feature: tf.io.FixedLenFeature(shape=[1], dtype=tf.float32)\n",
    "           for feature in _FEATURE_KEYS\n",
    "       },\n",
    "    _LABEL_KEY: tf.io.FixedLenFeature(shape=[1], dtype=tf.int64)\n",
    "}\n",
    "\n",
    "\n",
    "def _input_fn(file_pattern: List[str],\n",
    "              data_accessor: tfx.components.DataAccessor,\n",
    "              schema: schema_pb2.Schema,\n",
    "              batch_size: int) -> tf.data.Dataset:\n",
    "  \"\"\"Generates features and label for training.\n",
    "\n",
    "  Args:\n",
    "    file_pattern: List of paths or patterns of input tfrecord files.\n",
    "    data_accessor: DataAccessor for converting input to RecordBatch.\n",
    "    schema: schema of the input data.\n",
    "    batch_size: representing the number of consecutive elements of returned\n",
    "      dataset to combine in a single batch\n",
    "\n",
    "  Returns:\n",
    "    A dataset that contains (features, indices) tuple where features is a\n",
    "      dictionary of Tensors, and indices is a single Tensor of label indices.\n",
    "  \"\"\"\n",
    "  return data_accessor.tf_dataset_factory(\n",
    "      file_pattern,\n",
    "      tfxio.TensorFlowDatasetOptions(\n",
    "          batch_size=batch_size, label_key=_LABEL_KEY),\n",
    "      schema=schema).repeat()\n",
    "\n",
    "\n",
    "def _make_keras_model() -> tf.keras.Model:\n",
    "  \"\"\"Creates a DNN Keras model for classifying penguin data.\n",
    "\n",
    "  Returns:\n",
    "    A Keras Model.\n",
    "  \"\"\"\n",
    "  # The model below is built with Functional API, please refer to\n",
    "  # https://www.tensorflow.org/guide/keras/overview for all API options.\n",
    "  inputs = [keras.layers.Input(shape=(1,), name=f) for f in _FEATURE_KEYS]\n",
    "  d = keras.layers.concatenate(inputs)\n",
    "  for _ in range(2):\n",
    "    d = keras.layers.Dense(8, activation='relu')(d)\n",
    "  outputs = keras.layers.Dense(3)(d)\n",
    "\n",
    "  model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "  model.compile(\n",
    "      optimizer=keras.optimizers.Adam(1e-2),\n",
    "      loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "      metrics=[keras.metrics.SparseCategoricalAccuracy()])\n",
    "\n",
    "  model.summary(print_fn=logging.info)\n",
    "  return model\n",
    "\n",
    "\n",
    "# TFX Trainer will call this function.\n",
    "def run_fn(fn_args: tfx.components.FnArgs):\n",
    "  \"\"\"Train the model based on given args.\n",
    "\n",
    "  Args:\n",
    "    fn_args: Holds args used to train the model as name/value pairs.\n",
    "  \"\"\"\n",
    "\n",
    "  # This schema is usually either an output of SchemaGen or a manually-curated\n",
    "  # version provided by pipeline author. A schema can also derived from TFT\n",
    "  # graph if a Transform component is used. In the case when either is missing,\n",
    "  # `schema_from_feature_spec` could be used to generate schema from very simple\n",
    "  # feature_spec, but the schema returned would be very primitive.\n",
    "  schema = schema_utils.schema_from_feature_spec(_FEATURE_SPEC)\n",
    "\n",
    "  train_dataset = _input_fn(\n",
    "      fn_args.train_files,\n",
    "      fn_args.data_accessor,\n",
    "      schema,\n",
    "      batch_size=_TRAIN_BATCH_SIZE)\n",
    "  eval_dataset = _input_fn(\n",
    "      fn_args.eval_files,\n",
    "      fn_args.data_accessor,\n",
    "      schema,\n",
    "      batch_size=_EVAL_BATCH_SIZE)\n",
    "\n",
    "  model = _make_keras_model()\n",
    "  model.fit(\n",
    "      train_dataset,\n",
    "      steps_per_epoch=fn_args.train_steps,\n",
    "      validation_data=eval_dataset,\n",
    "      validation_steps=fn_args.eval_steps)\n",
    "\n",
    "  # The result of the training should be saved in `fn_args.serving_model_dir`\n",
    "  # directory.\n",
    "  model.save(fn_args.serving_model_dir, save_format='tf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-LsYx8MpYvPv"
   },
   "source": [
    "Copy the module file to GCS which can be accessed from the pipeline components.\n",
    "Because model training happens on GCP, we need to upload this model definition. \n",
    "\n",
    "Otherwise, you might want to build a container image including the module file\n",
    "and use the image to run the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "rMMs5wuNYAbc",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://penguin_trainer.py [Content-Type=text/x-python]...\n",
      "/ [1 files][  3.8 KiB/  3.8 KiB]                                                \n",
      "Operation completed over 1 objects/3.8 KiB.                                      \n"
     ]
    }
   ],
   "source": [
    "!gsutil cp {_trainer_module_file} {MODULE_ROOT}/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w3OkNz3gTLwM"
   },
   "source": [
    "### Write a pipeline definition\n",
    "\n",
    "We will define a function to create a TFX pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "M49yYVNBTPd4",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Copied from https://www.tensorflow.org/tfx/tutorials/tfx/penguin_simple and\n",
    "# slightly modified because we don't need `metadata_path` argument.\n",
    "\n",
    "def _create_pipeline(pipeline_name: str, pipeline_root: str, data_root: str,\n",
    "                     module_file: str, serving_model_dir: str,\n",
    "                     ) -> tfx.dsl.Pipeline:\n",
    "  \"\"\"Creates a three component penguin pipeline with TFX.\"\"\"\n",
    "  # Brings data into the pipeline.\n",
    "  example_gen = tfx.components.CsvExampleGen(input_base=data_root)\n",
    "\n",
    "  # Uses user-provided Python function that trains a model.\n",
    "  trainer = tfx.components.Trainer(\n",
    "      module_file=module_file,\n",
    "      examples=example_gen.outputs['examples'],\n",
    "      train_args=tfx.proto.TrainArgs(num_steps=100),\n",
    "      eval_args=tfx.proto.EvalArgs(num_steps=5))\n",
    "\n",
    "  # Pushes the model to a filesystem destination.\n",
    "  pusher = tfx.components.Pusher(\n",
    "      model=trainer.outputs['model'],\n",
    "      push_destination=tfx.proto.PushDestination(\n",
    "          filesystem=tfx.proto.PushDestination.Filesystem(\n",
    "              base_directory=serving_model_dir)))\n",
    "\n",
    "  # Following three components will be included in the pipeline.\n",
    "  components = [\n",
    "      example_gen,\n",
    "      trainer,\n",
    "      pusher,\n",
    "  ]\n",
    "\n",
    "  return tfx.dsl.Pipeline(\n",
    "      pipeline_name=pipeline_name,\n",
    "      pipeline_root=pipeline_root,\n",
    "      components=components)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mJbq07THU2GV"
   },
   "source": [
    "## Run the pipeline on Vertex Pipelines.\n",
    "\n",
    "TFX provides multiple orchestrators to run your pipeline. In this tutorial we\n",
    "will use the Vertex Pipelines together with the Kubeflow V2 dag runner."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7mp0AkmrPdUb"
   },
   "source": [
    "We need to define a runner to actually run the pipeline. You will compile\n",
    "your pipeline into our pipeline definition format using TFX APIs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "fAtfOZTYWJu-",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running bdist_wheel\n",
      "running build\n",
      "running build_py\n",
      "creating build/lib\n",
      "copying penguin_trainer.py -> build/lib\n",
      "installing to /var/tmp/tmpjoirzw87\n",
      "running install\n",
      "running install_lib\n",
      "copying build/lib/penguin_trainer.py -> /var/tmp/tmpjoirzw87/.\n",
      "running install_egg_info\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/setuptools/_distutils/cmd.py:79: SetuptoolsDeprecationWarning: setup.py install is deprecated.\n",
      "!!\n",
      "\n",
      "        ********************************************************************************\n",
      "        Please avoid running ``setup.py`` directly.\n",
      "        Instead, use pypa/build, pypa/installer or other\n",
      "        standards-based tools.\n",
      "\n",
      "        See https://blog.ganssle.io/articles/2021/10/setup-py-deprecated.html for details.\n",
      "        ********************************************************************************\n",
      "\n",
      "!!\n",
      "  self.initialize_options()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running egg_info\n",
      "creating tfx_user_code_Trainer.egg-info\n",
      "writing tfx_user_code_Trainer.egg-info/PKG-INFO\n",
      "writing dependency_links to tfx_user_code_Trainer.egg-info/dependency_links.txt\n",
      "writing top-level names to tfx_user_code_Trainer.egg-info/top_level.txt\n",
      "writing manifest file 'tfx_user_code_Trainer.egg-info/SOURCES.txt'\n",
      "reading manifest file 'tfx_user_code_Trainer.egg-info/SOURCES.txt'\n",
      "writing manifest file 'tfx_user_code_Trainer.egg-info/SOURCES.txt'\n",
      "Copying tfx_user_code_Trainer.egg-info to /var/tmp/tmpjoirzw87/./tfx_user_code_Trainer-0.0+afa8d5dfaf2942b08385545b5e095850331200a5d7a669b1791b3e7efcc5fdd9-py3.10.egg-info\n",
      "running install_scripts\n",
      "creating /var/tmp/tmpjoirzw87/tfx_user_code_Trainer-0.0+afa8d5dfaf2942b08385545b5e095850331200a5d7a669b1791b3e7efcc5fdd9.dist-info/WHEEL\n",
      "creating '/var/tmp/tmpp4gl8ety/tfx_user_code_Trainer-0.0+afa8d5dfaf2942b08385545b5e095850331200a5d7a669b1791b3e7efcc5fdd9-py3-none-any.whl' and adding '/var/tmp/tmpjoirzw87' to it\n",
      "adding 'penguin_trainer.py'\n",
      "adding 'tfx_user_code_Trainer-0.0+afa8d5dfaf2942b08385545b5e095850331200a5d7a669b1791b3e7efcc5fdd9.dist-info/METADATA'\n",
      "adding 'tfx_user_code_Trainer-0.0+afa8d5dfaf2942b08385545b5e095850331200a5d7a669b1791b3e7efcc5fdd9.dist-info/WHEEL'\n",
      "adding 'tfx_user_code_Trainer-0.0+afa8d5dfaf2942b08385545b5e095850331200a5d7a669b1791b3e7efcc5fdd9.dist-info/top_level.txt'\n",
      "adding 'tfx_user_code_Trainer-0.0+afa8d5dfaf2942b08385545b5e095850331200a5d7a669b1791b3e7efcc5fdd9.dist-info/RECORD'\n",
      "removing /var/tmp/tmpjoirzw87\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "PIPELINE_DEFINITION_FILE = PIPELINE_NAME + '_pipeline.json'\n",
    "\n",
    "runner = tfx.orchestration.experimental.KubeflowV2DagRunner(\n",
    "    config=tfx.orchestration.experimental.KubeflowV2DagRunnerConfig(),\n",
    "    output_filename=PIPELINE_DEFINITION_FILE)\n",
    "# Following function will write the pipeline definition to PIPELINE_DEFINITION_FILE.\n",
    "_ = runner.run(\n",
    "    _create_pipeline(\n",
    "        pipeline_name=PIPELINE_NAME,\n",
    "        pipeline_root=PIPELINE_ROOT,\n",
    "        data_root=DATA_ROOT,\n",
    "        module_file=os.path.join(MODULE_ROOT, _trainer_module_file),\n",
    "        serving_model_dir=SERVING_MODEL_DIR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fWyITYSDd8w4"
   },
   "source": [
    "The generated definition file can be submitted using kfp client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "tI71jlEvWMV7",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.pipeline_jobs:Creating PipelineJob\n"
     ]
    }
   ],
   "source": [
    "# docs_infra: no_execute\n",
    "from google.cloud import aiplatform\n",
    "from google.cloud.aiplatform import pipeline_jobs\n",
    "\n",
    "aiplatform.init(project=GOOGLE_CLOUD_PROJECT, location=GOOGLE_CLOUD_REGION)\n",
    "\n",
    "job = pipeline_jobs.PipelineJob(template_path=PIPELINE_DEFINITION_FILE,\n",
    "                                display_name=PIPELINE_NAME)\n",
    "job.run(sync=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L3k9f5IVQXcQ"
   },
   "source": [
    "Visit __Vertex AI > Pipelines__ in your Google Cloud Console page to see the progress.\n",
    "\n",
    "Click on your `penguin-vertex-pipelines-xxx` run:\n",
    "\n",
    "![pipeline_start](01_pipeline_start.png)\n",
    "\n",
    "Explore the information displayed in each step while you wait for the job to progress.\n",
    "\n",
    "On completion, your pipeline UI should look similar to this:\n",
    "\n",
    "![pipeline_end](02_pipeline_completed.png)\n",
    "\n",
    "This job will take about 15 minutes in total to complete. Once complete, return to the lab to check your progress."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "pknVo1kM2wI2"
   ],
   "name": "Simple TFX Pipeline for Vertex Pipelines",
   "provenance": [],
   "toc_visible": true
  },
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m128",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m128"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
